{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24754fe7-33b8-428b-a5bc-521cb7890c9b",
   "metadata": {},
   "source": [
    "# Εργασία για το Μαθημα Επεξεργασία Φυσικής Γλώσσας"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b77376-3cf6-4dcb-8c88-7c7999e13e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\cmakr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cmakr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\cmakr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cmakr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, sent_tokenize, FreqDist, ConditionalFreqDist, RegexpParser, ne_chunk, corpus\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot\n",
    "import pandas as pd\n",
    "import re\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b6c3ab-e642-42dd-98fd-a9c2fe399dca",
   "metadata": {},
   "source": [
    "## Naive Bayes import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3ed11-635d-4353-8420-ff4a6e54a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, classification_report, precision_recall_curve, confusion_matrix, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191f470-0aba-4168-9a47-d710a7e7f48a",
   "metadata": {},
   "source": [
    "Πηγή: https://medium.com/@shuv.sdr/na%C3%AFve-bayes-classification-in-python-f869c2e0dbf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e0764-75b7-4354-a6e1-24473770547c",
   "metadata": {},
   "source": [
    "## Word2Vec + Classifier import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd1fa18-7d25-46b5-813e-ff8a33bb5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf81a7-4e19-49e7-8d27-fa06835937f9",
   "metadata": {},
   "source": [
    "Πηγή: https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7477b5d9-22b3-4614-b815-2b336bc0b54f",
   "metadata": {},
   "source": [
    "# RNN (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360a7548-190a-4f95-af65-587e4e144c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdf52c0-4a07-4073-baaf-281a2d4ad136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Πίνακες μετρικών για όλα τα μοντέλα (global scope)\n",
    "accuracy_scores = {}\n",
    "precision_scores = {}\n",
    "recall_scores = {}\n",
    "f1_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4376f4e8-62ab-4839-ae46-55fcbe882396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mail_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de9746-15be-4943-9375-2dac59b88193",
   "metadata": {},
   "source": [
    "# Φιλτραρισμα και Ελεγχος email\n",
    "\n",
    "Μέχρι τον αλγόριθμό Naive Bayes κάνουμε κάποιους ελέγχους ως προς τα δεδομένα που διαβάζουμε"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18cbc7d-83ab-4c7b-b131-5491fdecc174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83fc700e-bbd1-48c0-be99-b8a008ad49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_df = df[df['Category'] == 'ham'].copy()\n",
    "spam_df = df[df['Category'] == 'spam'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ef3413-7ab1-439f-a8b6-befa528af9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Πλήθος των Email 4825\n"
     ]
    }
   ],
   "source": [
    "print('Πλήθος των Email', len(ham_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5c9d00-2491-4f07-9338-1319b4f820e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Πλήθος των Spam 747\n"
     ]
    }
   ],
   "source": [
    "print('Πλήθος των Spam', len(spam_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51501c82-fc55-40d0-a204-57f5370e8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Category                                            Message\n",
      "0        ham  Go until jurong point, crazy.. Available only ...\n",
      "1        ham                      Ok lar... Joking wif u oni...\n",
      "3        ham  U dun say so early hor... U c already then say...\n",
      "4        ham  Nah I don't think he goes to usf, he lives aro...\n",
      "6        ham  Even my brother is not like to speak with me. ...\n",
      "..       ...                                                ...\n",
      "112      ham                    Going for dinner.msg you after.\n",
      "113      ham  I'm ok wif it cos i like 2 try new things. But...\n",
      "115      ham  Wa, ur openin sentence very formal... Anyway, ...\n",
      "116      ham  As I entered my cabin my PA said, '' Happy B'd...\n",
      "118      ham  Goodo! Yes we must speak friday - egg-potato r...\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ham_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c600645b-255a-42f2-a4cc-614e6a9403af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = ham_df['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ed37db-9905-4cd5-acf8-80cc115b7bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Go until jurong point, crazy.. Available only ...\n",
      "1                          Ok lar... Joking wif u oni...\n",
      "3      U dun say so early hor... U c already then say...\n",
      "4      Nah I don't think he goes to usf, he lives aro...\n",
      "6      Even my brother is not like to speak with me. ...\n",
      "                             ...                        \n",
      "112                      Going for dinner.msg you after.\n",
      "113    I'm ok wif it cos i like 2 try new things. But...\n",
      "115    Wa, ur openin sentence very formal... Anyway, ...\n",
      "116    As I entered my cabin my PA said, '' Happy B'd...\n",
      "118    Goodo! Yes we must speak friday - egg-potato r...\n",
      "Name: Message, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ham_messages.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8ca682-02a2-4d74-82c1-5f9de68a9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_urls = 0\n",
    "total_emojis = 0\n",
    "total_emoticons = 0\n",
    "\n",
    "def clean_message(text):\n",
    "    global total_urls, total_emojis, total_emoticons\n",
    "\n",
    "    # Patterns\n",
    "    url_pattern = r\"http[s]?://\\S+|www\\.\\S+\"\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    emoticon_pattern = r\"[:;=8][\\-o\\*\\']?[\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\]\"\n",
    "\n",
    "    # Μέτρηση URLs\n",
    "    found_urls = re.findall(url_pattern, text)\n",
    "    total_urls += len(found_urls)\n",
    "\n",
    "    # Μέτρηση emojis\n",
    "    found_emojis = emoji_pattern.findall(text)\n",
    "    total_emojis += len(found_emojis)\n",
    "\n",
    "    # Μέτρηση emoticons\n",
    "    found_emoticons = re.findall(emoticon_pattern, text)\n",
    "    total_emoticons += len(found_emoticons)\n",
    "\n",
    "    # Καθαρισμός\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "    text = emoji_pattern.sub('', text)\n",
    "    text = re.sub(emoticon_pattern, '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1bf671-43a6-4bc2-b645-fe0bd4feb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = ham_messages.apply(clean_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a15fa542-ea5f-4650-ade6-891a0d5d5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Βρέθηκαν 2 url\n"
     ]
    }
   ],
   "source": [
    "print(\"Βρέθηκαν \" + str(total_urls) + \" url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd87e6a-1f81-45af-9585-05ed2857e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Βρέθηκαν 2 emojis\n"
     ]
    }
   ],
   "source": [
    "print(\"Βρέθηκαν \" + str(total_emojis) + \" emojis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41cb42ce-6335-4b2d-8345-2cc9a1742a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Βρέθηκαν 471 emoticons\n"
     ]
    }
   ],
   "source": [
    "print(\"Βρέθηκαν \" + str(total_emoticons) + \" emoticons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f8201c2-84c5-40b2-893a-e5915bd703cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Go until jurong point, crazy.. Available only ...\n",
      "1                          Ok lar... Joking wif u oni...\n",
      "3      U dun say so early hor... U c already then say...\n",
      "4      Nah I don't think he goes to usf, he lives aro...\n",
      "6      Even my brother is not like to speak with me. ...\n",
      "                             ...                        \n",
      "112                      Going for dinner.msg you after.\n",
      "113    I'm ok wif it cos i like 2 try new things. But...\n",
      "115    Wa, ur openin sentence very formal... Anyway, ...\n",
      "116    As I entered my cabin my PA said, '' Happy B'd...\n",
      "118    Goodo! Yes we must speak friday - egg-potato r...\n",
      "Name: Message, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ham_messages.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b1f7e0a-27cf-4538-8fbf-7ac34f495b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages_text = ' '.join(ham_messages.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb3340d4-140a-478a-a510-64729a9eacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_normalized = ham_messages_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "438e46f6-fdb5-4319-971f-03a359049a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensHam = word_tokenize(ham_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4c963b2-e9e6-4b3e-b6ab-6e1b5200430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensSentHam = sent_tokenize(ham_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb592970-097e-46d1-89f7-bc8b0ff77b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Πλήθος tokens messages ΠΡΙΝ το tokenization 349562\n"
     ]
    }
   ],
   "source": [
    "print('Πλήθος tokens messages ΠΡΙΝ το tokenization', len(ham_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4a89dbc-058f-406f-9dd9-3e76f74f15f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Πλήθος tokens messages ΜΕΤΑ το tokenization 83924\n"
     ]
    }
   ],
   "source": [
    "print('Πλήθος tokens messages ΜΕΤΑ το tokenization', len(tokensHam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a9ecd3-0f23-4f55-903e-f7d0f1415160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Πλήθος sentence messages ΜΕΤΑ το sent_tokenize 5771\n"
     ]
    }
   ],
   "source": [
    "print('Πλήθος sentence messages ΜΕΤΑ το sent_tokenize', len(tokensSentHam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fee09e-0bd0-491d-809c-1756753340cc",
   "metadata": {},
   "source": [
    "Παίρνει τη λίστα των αγγλικών stopwords από το NLTK και βάζει μόνο αυτές στο tokenize και αφαιρούνται σημεία στίξεις \n",
    "και λέξεις με όχι τόσο μεγάλη σημασία"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e44c33b-0bc3-4278-b5ee-2db6b3c47bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acaaf09f-f521-4ebb-a2b1-5fb5823e4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensHam = [word for word in tokensHam if word.isalpha() and word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440fbf2d-a188-4001-8949-ffc425d63f73",
   "metadata": {},
   "source": [
    "Εφαρμόζουμε τον αλγόρυθμο porter για το stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb8a1eb-0107-4477-af1a-0ee85d4a44f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7474d-0874-4093-9244-0f8ad81cb587",
   "metadata": {},
   "source": [
    "Ομαλοποιήσουμε τις λέξεις, ώστε διαφορετικές μορφές (π.χ. run, running, runs) να αντιμετωπίζονται ως ίδιες λέξεις"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f246e2d-70ee-45d0-ac41-7b5d0721c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensHam = [stemmer.stem(word) for word in tokensHam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1edcdb98-c9f7-4140-8cfd-e625ddab8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensHamPT = pos_tag(tokensHam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba45988f-2dcf-4541-ba3d-513d40fd2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('go', 'VB'), ('jurong', 'JJ'), ('point', 'NN'), ('crazi', 'NN'), ('avail', 'NN'), ('bugi', 'NN'), ('n', 'RB'), ('great', 'JJ'), ('world', 'NN'), ('la', 'NN'), ('e', 'VBP'), ('buffet', 'JJ'), ('cine', 'NN'), ('got', 'VBD'), ('amor', 'JJ'), ('wat', 'NN'), ('ok', 'IN'), ('lar', 'JJ'), ('joke', 'NN'), ('wif', 'NN'), ('u', 'JJ'), ('oni', 'NN'), ('u', 'JJ'), ('dun', 'NNS'), ('say', 'VBP'), ('earli', 'JJ'), ('hor', 'NN'), ('u', 'JJ'), ('c', 'JJ'), ('alreadi', 'NNS'), ('say', 'VBP'), ('nah', 'JJ'), ('think', 'VBP'), ('goe', 'JJ'), ('usf', 'JJ'), ('live', 'VBP'), ('around', 'IN'), ('though', 'IN'), ('even', 'RB'), ('brother', 'JJR'), ('like', 'IN'), ('speak', 'JJ'), ('treat', 'NN'), ('like', 'IN'), ('aid', 'NN'), ('patent', 'NN'), ('per', 'IN'), ('request', 'NN'), ('mell', 'NN'), ('oru', 'IN'), ('minnaminungint', 'NN'), ('nurungu', 'NNS'), ('vettam', 'VBP'), ('set', 'VBN'), ('callertun', 'JJ'), ('caller', 'NN'), ('press', 'NN'), ('copi', 'NN'), ('friend', 'VBP'), ('callertun', 'NN'), ('gon', 'NN'), ('na', 'TO'), ('home', 'NN'), ('soon', 'RB'), ('want', 'JJ'), ('talk', 'NN'), ('stuff', 'NN'), ('anymor', 'NN'), ('tonight', 'VBD'), ('k', 'JJ'), ('cri', 'NN'), ('enough', 'JJ'), ('today', 'NN'), ('search', 'NN'), ('right', 'RB'), ('word', 'NN'), ('thank', 'NN'), ('breather', 'NN'), ('promis', 'NN'), ('wont', 'NN'), ('take', 'VB'), ('help', 'NN'), ('grant', 'VB'), ('fulfil', 'JJ'), ('promis', 'NN'), ('wonder', 'NN'), ('bless', 'NN'), ('time', 'NN'), ('date', 'NN'), ('sunday', 'NN'), ('oh', 'IN'), ('k', 'NN'), ('watch', 'NN'), ('eh', 'NN'), ('u', 'JJ'), ('rememb', 'NN'), ('spell', 'NN'), ('name', 'NN'), ('ye', 'NNP'), ('v', 'NN'), ('naughti', 'NNS'), ('make', 'VBP'), ('v', 'JJ'), ('wet', 'NNS'), ('fine', 'JJ'), ('way', 'NN'), ('u', 'JJ'), ('feel', 'VB'), ('way', 'NN'), ('gota', 'NN'), ('b', 'VBP'), ('serious', 'JJ'), ('spell', 'NN'), ('name', 'NN'), ('go', 'VBP'), ('tri', 'JJ'), ('month', 'NN'), ('ha', 'NN'), ('ha', 'NN'), ('joke', 'VBD'), ('ü', 'NNP'), ('pay', 'NN'), ('first', 'RB'), ('lar', 'JJ'), ('da', 'NN'), ('stock', 'NN'), ('comin', 'NN'), ('aft', 'NN'), ('finish', 'NN'), ('lunch', 'NN'), ('go', 'VBP'), ('str', 'JJ'), ('lor', 'NN'), ('ard', 'NN'), ('smth', 'NN'), ('lor', 'NN'), ('u', 'JJ'), ('finish', 'JJ'), ('ur', 'NN'), ('lunch', 'NN'), ('alreadi', 'VBP'), ('ffffffffff', 'NN'), ('alright', 'JJ'), ('way', 'NN'), ('meet', 'NN'), ('sooner', 'NN'), ('forc', 'VBZ'), ('eat', 'JJ'), ('slice', 'NN'), ('realli', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(tokensHamPT[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b89416-25c9-4e32-9a22-e6d2d393bc3b",
   "metadata": {},
   "source": [
    "Καθαρισμός για όλα τα email σε νέα def με όλα τα πιο πάνω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed18c8a4-b6cb-448e-840b-af632d227fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message_all_func(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and non-alphabetic tokens\n",
    "    ## tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    # Stem\n",
    "    ## tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "580ecbc3-cb95-4d76-996b-cc52fb2fcd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedAllMessage = df['Message'].astype(str).apply(clean_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f31814e-9fe5-45be-bdb7-eb2be3722265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      go until jurong point, crazy.. available only ...\n",
      "1                          ok lar... joking wif u oni...\n",
      "2      free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      u dun say so early hor... u c already then say...\n",
      "4      nah i don't think he goes to usf, he lives aro...\n",
      "                             ...                        \n",
      "145                            yes see ya not on the dot\n",
      "146     whats the staff name who is taking class for us?\n",
      "147    freemsg why haven't you replied to my text? i'...\n",
      "148    ummma.will call after check in.our life will b...\n",
      "149                    k..i deleted my contact that why?\n",
      "Name: Message, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cleanedAllMessage[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67c7ebe2-6232-4f4d-b097-c7cdf47b4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanAllMessageFunc = cleanedAllMessage.astype(str).apply(clean_message_all_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b8cf7e0-4b8c-4a7c-b85c-d3c3c7008e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      go until jurong point , crazy .. available onl...\n",
      "1                        ok lar ... joking wif u oni ...\n",
      "2      free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      u dun say so early hor ... u c already then sa...\n",
      "4      nah i do n't think he goes to usf , he lives a...\n",
      "                             ...                        \n",
      "145                            yes see ya not on the dot\n",
      "146    whats the staff name who is taking class for us ?\n",
      "147    freemsg why have n't you replied to my text ? ...\n",
      "148    ummma.will call after check in.our life will b...\n",
      "149                 k .. i deleted my contact that why ?\n",
      "Name: Message, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cleanAllMessageFunc[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19baa7-3b53-418d-905c-9ae88f065670",
   "metadata": {},
   "source": [
    "## Naive Bayes Αλγόρυθμός"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833b3d2-c331-411f-a7e4-81d6e3284bb6",
   "metadata": {},
   "source": [
    "Ο Naive Bayes είναι ένας απλός αλλά ισχυρός αλγόριθμος ταξινόμησης, που βασίζεται στο θεώρημα του Bayes και χρησιμοποιείται κυρίως για προβλήματα επεξεργασίας κειμένου, όπως η ταξινόμηση email σε spam και ham.\n",
    "\n",
    "Κατά την εκπαίδευση, ο αλγόριθμος μαθαίνει πόσο συχνά εμφανίζεται κάθε λέξη σε κάθε κατηγορία (π.χ. spam ή ham).\n",
    "Κατά την πρόβλεψη, υπολογίζει την πιθανότητα ένα νέο μήνυμα να ανήκει σε κάθε κατηγορία, και το κατατάσσει εκεί που η πιθανότητα είναι μεγαλύτερη.\n",
    "\n",
    "Είναι γρήγορος, απλός και αποδοτικός, ακόμα και όταν τα δεδομένα είναι μεγάλα ή περιέχουν πολύ κείμενο.\n",
    "\n",
    "Το Naive Bayes θα συγκρίνει τις πιθανότητες και θα κατατάξει το email σε spam ή ham, ανάλογα με το ποιες λέξεις περιέχει και πόσο συχνές είναι σε κάθε κατηγορία."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ece388-6de6-4979-a0e6-ca7bb331aa72",
   "metadata": {},
   "source": [
    "Μετατροπή σε αριθμητικά χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97bed82f-5872-40ca-94d3-d57fc87aadc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vec = \u001b[43mCountVectorizer\u001b[49m()\n",
      "\u001b[31mNameError\u001b[39m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3295c77-5cb6-4fc9-b46e-5f22b6701d88",
   "metadata": {},
   "source": [
    "Χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188edc40-64b8-4148-9a74-d9f090a16007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec.fit_transform(cleanAllMessageFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee07c21-9d44-4902-9c63-293d2ad96c14",
   "metadata": {},
   "source": [
    "fit - > Μαθαίνει το λεξιλόγιο από τα δεδομένα σου.\n",
    "\n",
    "Δηλαδή «χτίζει» ένα λεξικό με όλες τις μοναδικές λέξεις που υπάρχουν στη λίστα cleanAllMessageFunc.\n",
    "\n",
    "transform -> Μετατρέπει κάθε κείμενο σε αριθμητικό διάνυσμα, με βάση:\n",
    "\n",
    "Πόσες φορές εμφανίζεται κάθε λέξη (στο CountVectorizer)\n",
    "\n",
    "Ή πόσο σημαντική είναι κάθε λέξη (στο TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975224b1-59d7-44d8-a372-bd11ed4d346f",
   "metadata": {},
   "source": [
    "Ετικέτες"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7786968-a61f-474c-9a4f-b2be6774c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abf360-6781-468c-b1d8-75696a8d55c3",
   "metadata": {},
   "source": [
    "### Εκπαίδευση - Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fdd8a-3937-4ee3-a8c9-543adcdc7cfd",
   "metadata": {},
   "source": [
    "X\tΤα χαρακτηριστικά (π.χ. λέξεις) των δεδομένων\n",
    "\n",
    "y\tΟι αντίστοιχες ετικέτες (π.χ. ham, spam)\n",
    "\n",
    "train_test_split\tΣυνάρτηση της scikit-learn\n",
    "\n",
    "test_size=0.25\tΤο 25% των δεδομένων θα πάει στο test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e6f78-1fcb-4f49-8ef2-650afa31fc10",
   "metadata": {},
   "source": [
    "X_train\t75% των χαρακτηριστικών για εκπαίδευση\n",
    "\n",
    "X_test\t25% των χαρακτηριστικών για δοκιμή\n",
    "\n",
    "y_train\tΕτικέτες για X_train\n",
    "\n",
    "y_test\tΕτικέτες για X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff2631-ddee-4d2c-9744-a671941a140b",
   "metadata": {},
   "source": [
    "Το random_state θα το κάνουμε 42 ώστε στην επαναληψιμότητα αποτελεσμάτων να είναι πάντα ό ίδιος διαχωρσισμός "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29eebd5-54ee-4065-b022-7655e77be6be",
   "metadata": {},
   "source": [
    "και θα προσθέσουμε και το stratify να είναι ίσο με y για να διατηρήσει τις ίδιες αναλογίες κατηγοριών (π.χ. spam/ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7489dcdb-81ce-4973-9e7f-c024b91453f5",
   "metadata": {},
   "source": [
    "Αν το y έχει 75% ham και 25% spam τότε και το y_train, y_test θα έχουν τι ίδια αναλογία"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9085c53-2cc7-44ed-aee2-7de63b5bede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba679119-2b5a-4e7e-9044-91ffe322d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf9c60-fead-4fd4-8518-e5fee204736f",
   "metadata": {},
   "source": [
    "Ο MultinomialNB() είναι μια υλοποίηση του Naive Bayes αλγορίθμου για διακριτά (count-based) δεδομένα, και χρησιμοποιείται κυρίως στην ταξινόμηση κειμένου.\n",
    "\n",
    "Ιδανικός για αριθμητικά χαρακτηριστικά όπως οι μετρήσεις λέξεων: π.χ. πόσες φορές εμφανίζεται κάθε λέξη σε ένα email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c98e6f-9e79-4d93-8a04-638231af9ddb",
   "metadata": {},
   "source": [
    "Αυτό εκπαιδεύει το μοντέλο. Δηλαδή:\n",
    "\n",
    "Παίρνει τα X_train → τα χαρακτηριστικά (π.χ. word counts ή TF-IDF vectors)\n",
    "\n",
    "Παίρνει τα y_train → τις ετικέτες (π.χ. \"spam\" ή \"ham\")\n",
    "\n",
    "Υπολογίζει τις πιθανότητες που χρειάζεται για να κάνει μελλοντική πρόβλεψη (π.χ. \"αν βλέπω τη λέξη free, πόσο πιθανό είναι να είναι spam;\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169b78b-6851-423b-b3b3-88a28b62dc31",
   "metadata": {},
   "source": [
    "Από εδώ και πέρα, το μοντέλο έχει μάθει ποιες λέξεις ή συνδυασμοί λέξεων εμφανίζονται συχνότερα σε spam ή ham, και μπορεί να προβλέψει νέα παραδείγματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacdccb-05f6-4564-b6f9-ccb00297067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_test_array = np.array(y_test)\n",
    "y_pred_array = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32250730-c3a9-404d-b05d-3494d49e4057",
   "metadata": {},
   "source": [
    "classifier.predict(X_test) -> Αυτή η γραμμή κάνει πρόβλεψη στις δοκιμαστικές εισόδους:\n",
    "\n",
    "Το X_test είναι ο πίνακας με τα email του test set (μετασχηματισμένα σε vectors).\n",
    "\n",
    "Ο classifier έχει ήδη εκπαιδευτεί με X_train και y_train.\n",
    "\n",
    "Το αποτέλεσμα y_pred είναι ένας πίνακας με προβλέψεις (\"spam\" ή \"ham\"), για κάθε email του test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db8921-ff0d-414c-aaa8-c8adb1675791",
   "metadata": {},
   "source": [
    "Accuracy: Ποσοστό των σωστών προβλέψεων συνολικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116ecfe-6166-4572-a6eb-c65934fc5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6a907-bea8-48e6-ac1f-c255f1e8244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b3a7f-3e33-4bfa-aac0-8583e287f0b9",
   "metadata": {},
   "source": [
    "Το 97% των προβλέψεων ήταν σωστές συνολικά"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efb451-ac48-4c11-8157-aec67b8f2409",
   "metadata": {},
   "source": [
    "Precision: Από τα \"spam\" που είπε ο αλγόριθμος, πόσα ήταν σωστά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb3fef-3785-4493-a99a-33dda4fb8009",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76c236-5fbc-4332-b04a-2e1a73960e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision : {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91aafeb-beb2-4d3d-96a8-2a4c4d0dc703",
   "metadata": {},
   "source": [
    "Από τα μηνύματα που προβλέφθηκαν ως spam, το 85% ήταν όντως spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3900e26-0555-442e-8042-b8fa52e0c4b8",
   "metadata": {},
   "source": [
    "F1 Score\tΜέσος όρος Precision και Recall (harmonic mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622abc6-9f29-4399-87ff-d89ec1e4d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_spam = f1_score(y_test, y_pred, pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422d2a3-d16f-4a9f-b413-14d89083bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score spam : {f1_spam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556341a0-aa5a-42a8-8be1-8f70472e47b5",
   "metadata": {},
   "source": [
    "Recall\tΑπό τα πραγματικά spam, πόσα αναγνώρισε το μοντέλο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6e7c6-bc86-493d-afc5-419444fd8c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred, pos_label='spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b30e92-7509-4295-ae0c-5ef998e235e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recall    : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e33774-c389-4096-ab2d-144a84446076",
   "metadata": {},
   "source": [
    "Από τα πραγματικά spam, εντοπίστηκε το 89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca11db-fecc-4bd9-b3ed-63022eb0a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Προσθήκη αποτελεσματων για το Naive Βαυεσ\n",
    "accuracy_scores[\"Naive Bayes\"] = accuracy\n",
    "precision_scores[\"Naive Bayes\"] = precision\n",
    "recall_scores[\"Naive Bayes\"] = recall\n",
    "f1_scores[\"Naive Bayes\"] = f1_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaba08b-3dac-40dd-8bae-735eae1197a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d47192-116e-4d81-a215-f69ecb42a1ed",
   "metadata": {},
   "source": [
    "Πάνω αριστερά: σωστά ham\n",
    "\n",
    "Κάτω δεξιά: σωστά spam\n",
    "\n",
    "Πάνω δεξιά: λάθος spam σε ham ➜ false positives\n",
    "\n",
    "Κάτω αριστερά: λάθος ham σε spam ➜ false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03761419-67bc-44a1-9c5d-785bf60127bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αν y_test είναι Series με labels \"spam\"/\"ham\", το μετατρέπουμε σε binary (π.χ. 1=spam, 0=ham)\n",
    "y_test_bin = (y_test == 'spam').astype(int)\n",
    "\n",
    "# Προβλέψεις πιθανοτήτων για την κλάση \"spam\"\n",
    "y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Precision-Recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_bin, y_pred_proba)\n",
    "\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots(figsize=(6, 6))\n",
    "ax.plot(recall, precision, label='Naive Bayes Classification', color='firebrick')\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.legend()\n",
    "matplotlib.pyplot.grid(True)\n",
    "matplotlib.pyplot.box(False)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc89d7-6f99-4a33-ba1b-02cf885d2c23",
   "metadata": {},
   "source": [
    "Ο άξονας Χ (Recall): Πόσα από τα πραγματικά spam εντοπίστηκαν.\n",
    "\n",
    "Ο άξονας Υ (Precision): Από τα όσα το μοντέλο είπε ότι είναι spam, πόσα ήταν σωστά.\n",
    "\n",
    "Ιδανικά θες ψηλά Precision και ψηλό Recall, αλλά υπάρχει συνήθως trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1289b-3274-428e-a056-1b0906221849",
   "metadata": {},
   "source": [
    "Το μεγαλύτερο μέρος της γραμμής είναι πολύ ψηλά (Precision ≈ 1.0).\n",
    "\n",
    "Αυτό σημαίνει ότι το μοντέλο σου είναι πολύ σίγουρο όταν προβλέπει κάτι ως spam — σχεδόν πάντα έχει δίκιο.\n",
    "\n",
    "Όμως, προς το τέλος, η Precision πέφτει απότομα καθώς αυξάνεται το Recall:\n",
    "\n",
    "Το μοντέλο αρχίζει να εντοπίζει περισσότερα spam, αλλά αρχίζει να κάνει περισσότερα λάθη (False Positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dbb39-85eb-4120-9459-57fa0d2fff34",
   "metadata": {},
   "source": [
    "### Παρατήρηση"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af914dff-8210-411e-81ed-329f07cbc602",
   "metadata": {},
   "source": [
    "Τα δεδομένα που χρησιμοποιεί ο αλγόριθμος έχουν υποστεί μόνο βασικό καθαρισμό, όπως αφαίρεση URLs, εικονιδίων (icons), emojis και μετατροπή σε πεζά (lowercase). Δεν έχει εφαρμοστεί περαιτέρω επεξεργασία.\n",
    "\n",
    "Σε περίπτωση που εφαρμόσουμε μια συνάρτηση που περιλαμβάνει αφαίρεση stopwords και stemming, παρατηρείται σημαντική πτώση στην απόδοση του μοντέλου, τόσο ως προς την ακρίβεια (Accuracy), όσο και ως προς τις μετρικές Precision, Recall και F1 Score.\n",
    "\n",
    "Αυτό θεωρείται αναμενόμενο, καθώς ο στόχος μας είναι η ταξινόμηση των κανονικών μηνυμάτων (ham) και των ανεπιθύμητων (spam). Η εφαρμογή αφαίρεσης stopwords οδηγεί στην απώλεια λέξεων-κλειδιών που συχνά χαρακτηρίζουν τα spam, όπως \"free\", \"win\", \"now\", κ.ά. Επιπλέον, με την εφαρμογή stemming, αλλοιώνεται η μορφολογική δομή των λέξεων που απομένουν, γεγονός που μπορεί να μειώσει την ικανότητα του μοντέλου να αναγνωρίσει μοτίβα. Συνεπώς, η υπερβολική επεξεργασία ενδέχεται να αφαιρέσει κρίσιμη σημασιολογική πληροφορία, επηρεάζοντας αρνητικά την τελική ταξινόμηση."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d86e7-3d3a-424c-9c42-a00c1b2c4fa1",
   "metadata": {},
   "source": [
    "## Word2Vec + Classifier \n",
    "\n",
    "Το Word2Vec + Classifier είναι ένας συνδυασμός τεχνικών επεξεργασίας φυσικής γλώσσας και μηχανικής μάθησης, όπου τα κείμενα μετατρέπονται πρώτα σε αριθμητικά διανύσματα μέσω του Word2Vec και στη συνέχεια ταξινομούνται με τη βοήθεια ενός αλγορίθμου ταξινόμησης, όπως η LogisticRegression. Το Word2Vec μαθαίνει να αναπαριστά τις λέξεις σε ένα νοηματικό χώρο, διατηρώντας σχέσεις ομοιότητας, ενώ ο ταξινομητής χρησιμοποιεί αυτές τις αναπαραστάσεις για να προβλέψει την κατηγορία κάθε μηνύματος (π.χ. ham ή spam).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661c064-cefe-4312-84a2-5982616ac62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Εκπαίδευση Word2Vec\n",
    "w2v_model = gensim.models.Word2Vec(cleanedAllMessage,\n",
    "                                   vector_size=100,\n",
    "                                   window=5,\n",
    "                                   min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134f5f0-da94-4aa4-bacc-02865a714d40",
   "metadata": {},
   "source": [
    "Εδώ ο αλγόριθμός κάνει κάθε λέξη ένα διάνυσμα 100 διαστάσεων και αναλόγως το πόσο κοντά εμφανίζεται κάθε λέξη έχει και κοντινά διανίσματα.\n",
    "\n",
    "cleanedAllMessage: Η λιστα απο τα email που έχουν γίνει tokenization\n",
    "\n",
    "vector_size=100: Κάθε λέξη θα εκπροσωπείται με διάνυσμα 100 διαστάσεων\n",
    "\n",
    "window=5: Το Word2Vec \"βλέπει\" 5 λέξεις πριν και 5 μετά για να μάθει τη σχέση ανάμεσα σε λέξεις\n",
    "\n",
    "min_count=2: Αγνοεί λέξεις που εμφανίζονται λιγότερο από 2 φορές στο σύνολο δεδομένων (θεωρούνται ασήμαντες)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5f292-6a6b-410d-8054-e146735cfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    valid_tokens = [word for word in sentence if word in w2v_model.wv.key_to_index]\n",
    "    if not valid_tokens:\n",
    "        return [0]*w2v_model.vector_size\n",
    "    return w2v_model.wv[valid_tokens].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b186b-646e-41d2-bff9-93ec177e502d",
   "metadata": {},
   "source": [
    "Παίρνει όλα τα διανύσματα των έγκυρων λέξεων και επιστρέφει τον μέσο όρο. \n",
    "\n",
    "Γιατί το Word2Vec δουλεύει σε επίπεδο λέξεων, αλλά ο ταξινομητής χρειάζεται ένα διάνυσμα για όλο το μήνυμα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601bef79-18d9-4e7f-a539-55d3894f1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorW2V = cleanedAllMessage.apply(vectorize) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab24d6-59fa-466a-9852-15829f118715",
   "metadata": {},
   "source": [
    "Άρα παίρνουμε τον μέσο όρο των λέξεων που περιέχει το κάθε μήνυμα → ώστε να φτιάξουμε ένα αντιπροσωπευτικό \"προφίλ\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3efaa1-8d92-41d2-ad5f-4a49bdcf2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorW2V.tolist()\n",
    "y = df['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799193f6-8e5d-4cb0-adca-ad08c98a7485",
   "metadata": {},
   "source": [
    "Μετατρέπει τη Pandas Series που περιέχει τα διανύσματα μηνυμάτων (Word2Vec) σε λίστα Python.\n",
    "\n",
    "Το X είναι λίστα διανυσμάτων\n",
    "\n",
    "Παίρνει τη στήλη Category από το αρχικό df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682b672-5408-48fd-b026-52d98db6d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.25, random_state = 42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259309a-b1ec-48f2-b2fc-0044804e08a2",
   "metadata": {},
   "source": [
    "X_train\tΔεδομένα για εκπαίδευση (διανύσματα) -> Είναι τα δεδομένα που θα \"δει\" το μοντέλο στην εκπαίδευση. Κάθε στοιχείο είναι ένα διάνυσμα που αναπαριστά ένα μήνυμα (από Word2Vec).\n",
    "\n",
    "X_test\tΔεδομένα για έλεγχο -> Είναι τα δεδομένα που δεν έχει ξαναδεί το μοντέλο. Χρησιμοποιούνται για να δοκιμάσουμε την ακρίβειά του.\n",
    "\n",
    "y_train\tΣωστές κατηγορίες για τα X_train -> Περιέχει τις σωστές απαντήσεις για κάθε μήνυμα του X_train. Είναι ham ή spam.\n",
    "\n",
    "y_test\tΣωστές κατηγορίες για τα X_test -> Οι σωστές απαντήσεις για τα μηνύματα του X_test. Τις χρησιμοποιούμε για σύγκριση με τις προβλέψεις του μοντέλου."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c536c-c26c-4587-9769-ecb24f3ea928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Εκπαίδευση classifier (Logistic Regression)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a52db-beac-4a40-bbf9-dc3a41776125",
   "metadata": {},
   "source": [
    "Εδώ θα χρισημοποιήσουμε τον LogisticRegression αντι του MultinomialNB(), γιατί τα δεδομένα μας είναι διανύσματα. \n",
    "\n",
    "Καταμέτρηση λέξεων\tMultinomialNB()\n",
    "\n",
    "Διανύσματα λέξεων (Word2Vec, Embeddings)\tLogisticRegression, SVC, RandomForest, KNN, κ.ά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d437510-938c-4b2f-a3d8-0f562b88ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eef750-5948-4df5-8f79-602b7ef4eea7",
   "metadata": {},
   "source": [
    "predict() ζητάει από το μοντέλο να προβλέψει αν κάθε μήνυμα είναι ham ή spam στα διανύσματα που έχει το X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563e4bf-6f48-403e-98c0-16ba713a5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bba1f1-a970-42d2-9a5e-50ff3b3b673c",
   "metadata": {},
   "source": [
    "Το ποσοστό των σωστών προβλέψεων του μοντέλου είναι 96%\n",
    "\n",
    "Συγκρίνει τις πραγματικές ετικέτες (y_test) με τις προβλεπόμενες (y_pred), και μετρά πόσες ήταν σωστές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806de2c-632c-48d7-b74b-f5640c3ee80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "print(f\"Precision : {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92003065-6b01-4a27-bf26-77540986cdc6",
   "metadata": {},
   "source": [
    "Από όλα τα μηνύματα που προβλέψαμε ως spam το 93% είναι σωστό"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22e4f2-1502-4686-a32e-9db4d3a1203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "print(f\"Recall    : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c15de6-533e-49f3-b613-646ba40ada9e",
   "metadata": {},
   "source": [
    "Από όλα τα πραγματικά spam μηνύματα στο test set, κατάφερε να βρει το μοντέλο μας 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7b4ba-0545-47bb-8187-72ced292c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "print(f\"F1 Score  : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ce3e8-24dc-48a4-90ec-c325393713b1",
   "metadata": {},
   "source": [
    "Το F1 Score είναι ένας συνδυασμός του Precision και του Recall.\n",
    "Συγκεκριμένα, είναι ο αρμονικός μέσος όρος των δύο:\n",
    "\n",
    "F1 = 2* (precision * recall / precision + recall)\n",
    "\n",
    "Ο ταξινομητής Word2Vec + Logistic Regression πέτυχε F1 Score 87.82%, γεγονός που δείχνει πολύ καλή γενική απόδοση.\n",
    "\n",
    "Το μοντέλο μας εντοπίζει αποτελεσματικά τα spam emails, ισορροπώντας την ακρίβεια με την ικανότητα εντοπισμού."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29be10e-d611-413a-8c84-8a58b1b5316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Προσθήκη αποτελεσματων για το Word2Vec\n",
    "accuracy_scores[\"Word2Vec\"] = accuracy\n",
    "precision_scores[\"Word2Vec\"] = precision\n",
    "recall_scores[\"Word2Vec\"] = recall\n",
    "f1_scores[\"Word2Vec\"] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464708e-5c43-4ea7-8f02-39cc763d7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316176d1-fda4-4a8d-b62b-58c47241cd86",
   "metadata": {},
   "source": [
    "Πάνω αριστερά: σωστά ham\n",
    "\n",
    "Κάτω δεξιά: σωστά spam\n",
    "\n",
    "Πάνω δεξιά: λάθος spam σε ham ➜ false positives\n",
    "\n",
    "Κάτω αριστερά: λάθος ham σε spam ➜ false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc5c40-c84c-418d-80c0-74f17918c9cc",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "Ο RNN (Recurrent Neural Network) είναι ένας τύπος νευρωνικού δικτύου που έχει σχεδιαστεί ειδικά για να επεξεργάζεται ακολουθίες δεδομένων, όπως:\n",
    "\n",
    "προτάσεις (σειρές λέξεων)\n",
    "\n",
    "Τον ξεχωρίζει:\n",
    "\n",
    "Σε αντίθεση με τα απλά νευρωνικά δίκτυα, ο RNN θυμάται πληροφορίες από προηγούμενα βήματα της ακολουθίας. Δηλαδή: Η έξοδος κάθε χρονικής στιγμής επηρεάζεται όχι μόνο από το τρέχον στοιχείο της ακολουθίας, αλλά και από ό,τι έχει προηγηθεί.\n",
    "\n",
    "Παράδειγμα:\n",
    "Αν επεξεργάζεσαι το μήνυμα: \"I love pizza\"\n",
    "το RNN διαβάζει λέξη-λέξη, και μεταφέρει πληροφορία από το \"I\" στο \"love\" και μετά στο \"pizza\" — διατηρώντας μια μνήμη της πρότασης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea48648-189f-40d4-9212-29962ef618c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Χρησιμοποιούμε τα cleaned μηνύματα\n",
    "texts = [' '.join(tokens) for tokens in cleanedAllMessage]\n",
    "labels = df['Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b872b-04ab-428a-a5cd-107be6c4dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Μετατροπή κατηγορίας σε 0/1\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8dc42f-6cf6-4bf8-b65f-ee12a1c3a1e9",
   "metadata": {},
   "source": [
    "Μετατρέπουμε τις κατηγορικές ετικέτες (labels), π.χ. 'ham', 'spam', σε αριθμούς (0 και 1) \n",
    "ώστε να μπορούν να χρησιμοποιηθούν από τα μοντέλα μηχανικής μάθησης.\n",
    "\n",
    "Παίρνει το array le με τις κατηγορίες (π.χ.): le = ['ham', 'ham', 'spam', 'ham', 'spam']\n",
    "\n",
    "Και\n",
    "\n",
    "y = [0, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea22a25-cf4d-482e-b2fd-e9187bc8afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization και sequences\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da544451-5b30-4f65-8268-573c7a0f0ed8",
   "metadata": {},
   "source": [
    "Εδώ δημιουργούμε ένα Tokenizer αντικείμενο από το Keras, το οποίο:\n",
    "\n",
    "Με παραμέτρους\n",
    "\n",
    "num_words=5000 -> Κρατάει τις 5.000 πιο συχνές λέξεις από το σύνολο των email\n",
    "\n",
    "oov_token='<OOV>' -> Δημιουργούμε ειδικό token για λέξεις εκτός λεξιλογίου (Out-Of-Vocabulary)\n",
    "\n",
    "Αυτό σημαίνει ότι όλες οι σπάνιες λέξεις (εκτός των 5.000 πιο συχνών) θα αντικατασταθούν με τον αριθμό που αντιστοιχεί στο <OOV> token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008d973-30d2-47e3-a2ff-12aa773a7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization και sequences\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6200b-8da4-4d3d-8ddc-f9cbde66a2fe",
   "metadata": {},
   "source": [
    "\"Εκπαιδεύουμε\" τον tokenizer πάνω στα δεδομένα κειμένου:\n",
    "\n",
    "Μετράει πόσες φορές εμφανίζεται κάθε λέξη\n",
    "\n",
    "Αναθέτει σε κάθε λέξη έναν μοναδικό ακέραιο αριθμό ID\n",
    "\n",
    "πχ\n",
    "\n",
    "tokenizer.word_index:\n",
    "{\n",
    "  'free': 1,\n",
    "  'win': 2,\n",
    "  'prize': 3,\n",
    "  'spam': 4,\n",
    "  ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6145960-b604-48f6-9b3a-79e25779aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565777e-38eb-40bc-b386-d24067c00bec",
   "metadata": {},
   "source": [
    "Μετατρέπει κάθε email σε λίστα αριθμών, όπου κάθε αριθμός είναι το ID της λέξης.\n",
    "\n",
    "πχ\n",
    "texts = [\"win free\", \"free prize\"]\n",
    "sequences = [[2, 1], [1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414aa993-6fc5-4d11-96e8-76693619cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding (όλες οι ακολουθίες στο ίδιο μήκος)\n",
    "maxlen = 100\n",
    "X = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e7849-cb17-4992-92cb-c4ddc111230b",
   "metadata": {},
   "source": [
    "Το pad_sequences το χρησιμοποιούμε για να κανονικοποιήσουμε το μήκος όλων των ακολουθιών λέξεων (token IDs), ώστε να έχουν ίδιο μήκος — κάτι που απαιτείται από το RNNs και άλλα νευρωνικά δίκτυα.\n",
    "\n",
    "Τι κάνει ακριβός\n",
    "\n",
    "κάθε email θα μετατραπεί σε ακολουθία μήκους 100 αριθμών\n",
    "\n",
    "αν είναι μικρότερο → θα προστεθούν μηδενικά μπροστά\n",
    "\n",
    "αν είναι μεγαλύτερο → θα κοπεί από την αρχή ή το τέλος\n",
    "\n",
    "Βάζουμε μήκος 100 maxlen γιατί θεωρουμε ότι όλα τα email δεν θα ξεπερνάνε το μήκος λέξεων τον 120.\n",
    "\n",
    "πχ\n",
    "Απο\n",
    "sequences = [\n",
    "    [10, 4, 2],\n",
    "    [3, 8],\n",
    "    [1]\n",
    "]\n",
    "Σε\n",
    "X =\n",
    "[\n",
    " [0, 0, 10, 4, 2],\n",
    " [0, 0, 0, 3, 8],\n",
    " [0, 0, 0, 0, 1]\n",
    "]\n",
    "\n",
    "Γιατί sequence\n",
    "\n",
    "Η χρήση sequences σε προβλήματα όπως η ταξινόμηση email (π.χ. spam/ham) δεν είναι τυχαία — είναι κρίσιμο βήμα για να μετατρέψουμε κείμενο σε μορφή που καταλαβαίνουν τα νευρωνικά δίκτυα.\n",
    "\n",
    "Τα μοντέλα όπως τα RNN, LSTM, CNN, BERT:\n",
    "\n",
    "ΔΕΝ μπορούν να δουλέψουν απευθείας με συμβολοσειρές (π.χ. 'free prize')\n",
    "\n",
    "Χρειάζονται αριθμητική αναπαράσταση (π.χ. [1, 42])\n",
    "\n",
    "Άρα, το sequence είναι η ψηφιακή μετάφραση του κειμένου.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67289b8d-98bc-4801-9856-cfef31616d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f002d-6aa5-4cfb-ac72-3fa9bf65051b",
   "metadata": {},
   "source": [
    "Σε αυτό το βήμα κάνουμε τον διαχωρισμό των δεδομένων σε εκπαίδευση και δοκιμή (train/test split), κάτι που είναι βασικό βήμα σε κάθε μοντέλο μηχανικής μάθησης ή deep learning.\n",
    "\n",
    "X ->\tΤα δεδομένα εισόδου (π.χ. tokenized και padded emails)\n",
    "\n",
    "y ->\tΟι αντίστοιχες ετικέτες (π.χ. spam, ham)\n",
    "\n",
    "test_size=0.25 ->\tΚρατά το 25% των δεδομένων για δοκιμή και το υπόλοιπο 75% για εκπαίδευση\n",
    "\n",
    "stratify=y ->\tΔιατηρεί την ίδια αναλογία spam/ham και στα δύο σύνολα (train και test)\n",
    "\n",
    "random_state=42 ->\tΕξασφαλίζει ότι ο διαχωρισμός θα είναι επαναλήψιμος (για ίδιους αριθμούς κάθε φορά)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208e8c6-0bcd-42a1-b7d4-7f05c55fc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Input(shape=(100,)), \n",
    "    tf.keras.layers.Embedding(input_dim=5000, output_dim=64),\n",
    "    tf.keras.layers.SimpleRNN(32, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f593d2-b5f7-41df-aa01-4ccbe6825274",
   "metadata": {},
   "source": [
    "Το μοντέλο μας εδώ είναι ένα νευρωνικό δίκτυο βασισμένο σε RNN (Recurrent Neural Network) για δυαδική ταξινόμηση, όπως η διάκριση email σε spam ή ham.\n",
    "\n",
    "Δηλώνουμε ότι κάθε δείγμα εισόδου είναι ακολουθία 100 tokens Input(shape=(100,)).\n",
    "\n",
    "Μετατρέπουμε κάθε token (π.χ. 52, 731) σε διάνυσμα 64 διαστάσεων Embedding(input_dim=5000, output_dim=64) -> Τελικό output σχήμα: (100, 64) → δηλαδή, 100 λέξεις με 64 διαστάσεις η καθεμία..\n",
    "\n",
    "SimpleRNN(32, activation='tanh') εδώ είναι το RNN layer. Παίρνει ως είσοδο τη σειρά των embeddings και προσπαθεί να \"θυμηθεί\" patterns στην ακολουθία.Επισης Διατηρεί κατάσταση (state) μέσα στην ακολουθία, π.χ. \"αν είδα τη λέξη 'win' και μετά 'money'\".Εδώ χρησιμοποιούμε το tanh γιατί βοηθά να διατηρηθεί ισορροπία θετικών/αρνητικών τιμών και είναι κατάλληλο για μνήμη.\n",
    "\n",
    "Για να αποφευχθεί overfitting, ρίχνουμε τυχαία το 30% των συνδέσεων κατά την εκπαίδευση. Dropout(0.3)\n",
    "\n",
    "Πιο συγκεκριμέμα το Dropout \"απενεργοποιεί\" τυχαία το 30% των νευρώνων του προηγούμενου layer σε κάθε βήμα.\n",
    "Αυτό σημαίνει ότι δεν αφήνει το δίκτυο να εξαρτάται υπερβολικά από συγκεκριμένους νευρώνες.Το Dropout \"αναγκάζει\" το δίκτυο να μάθει πιο γενικά πρότυπα, όχι απλώς να παπαγαλίζει.\n",
    "\n",
    "Dense(1, activation='sigmoid') -> Τελική έξοδος: ένα νούμερο μεταξύ 0 και 1. \n",
    "Με sigmoid ενεργοποίηση, ερμηνεύεται ως:\n",
    "κοντά στο 0 → ham\n",
    "κοντά στο 1 → spam\n",
    "\n",
    "Αυτή η τιμή ερμηνεύεται ως πιθανότητα:\n",
    "\n",
    "π.χ. 0.95 → πολύ πιθανό να είναι spam\n",
    "\n",
    "π.χ. 0.02 → πολύ πιθανό να είναι ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc5b3a-cb87-4300-9e59-91b5cac8a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e32c8f-9843-4149-a3fb-a067d595dadc",
   "metadata": {},
   "source": [
    "Ενα απο τα πιο σημαντικά βήματα συνοψήζη και προετοιμάζει το μοντέλο μας πρίν την εκπαίδευση.\n",
    "\n",
    "model.compile(...) - > Λέει στον tensorFlow πως να εκπαιδευση το μοντέλο μας:\n",
    "\n",
    "loss='binary_crossentropy' -> Το χρησιμοποιόυμε για δυαδική ταξινόμηση (0 = ham, 1 = spam).\n",
    "\n",
    "Υπολογίζει πόσο κακή είναι η πρόβλεψη σε σχέση με την πραγματική ετικέτα.\n",
    "\n",
    "Βασίζεται στην πιθανότητα που δίνει η sigmoid του μοντέλου. Παράδειγμα: Αν το μοντέλο λέει ότι είναι spam με πιθανότητα 0.9 αλλά είναι ham (0), η τιμωρία (loss) θα είναι μεγάλη.\n",
    "\n",
    "optimizer='adam':\n",
    "\n",
    "Είναι ο βελτιστοποιητής που προσαρμόζει τα βάρη του μοντέλου κατά την εκπαίδευση.\n",
    "\n",
    "adam = Adaptive Moment Estimation: πολύ καλός και γρήγορος για κείμενο.\n",
    "\n",
    "metrics=['accuracy']:\n",
    "\n",
    "Ζητάμε να παρακολουθεί την ακρίβεια (accuracy) κατά την εκπαίδευση.Δηλαδή: Πόσες προβλέψεις είναι σωστές / σύνολο δειγμάτων\n",
    "\n",
    "\n",
    "Embedding ->\tΜαθαίνει να μετατρέπει κάθε λέξη σε διάνυσμα νοήματος\n",
    "\n",
    "SimpleRNN ->\tΜαθαίνει να μαθαίνει τη \"σειρά\" των λέξεων και κρατάει μνήμη\n",
    "\n",
    "Dense -> \tΜαθαίνει να βγάζει την τελική πρόβλεψη (spam ή ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47f981-e12b-4d57-98e1-61f8efa3b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca37a2-e748-4c67-a642-83991e18560e",
   "metadata": {},
   "source": [
    "Εδώ εκπαιδέυουμε το μοντέλο μας \n",
    "\n",
    "Αυτά είναι τα δεδομένα εκπαίδευσης:\n",
    "\n",
    "X_train: οι είσοδοι (π.χ. μηνύματα email μετασχηματισμένα σε ακολουθίες αριθμών)\n",
    "\n",
    "y_train: οι αντίστοιχες ετικέτες (π.χ. spam ή ham)\n",
    "\n",
    "epochs=5\n",
    "\n",
    "Ορίζει πόσες φορές θα δει το μοντέλο όλο το εκπαιδευτικό σύνολο.\n",
    "\n",
    "Π.χ. αν έχεις 1000 emails και epochs=5, το μοντέλο θα εκπαιδευτεί πάνω στα ίδια 1000 emails 5 φορές.\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "Καθορίζει πόσα δείγματα (emails) θα επεξεργάζεται το μοντέλο ταυτόχρονα πριν κάνει μία ενημέρωση των βαρών.\n",
    "\n",
    "Αν έχεις 1000 δείγματα, θα κάνει:\n",
    "\n",
    "1000 / 32 ≈ 32 \"μίνι-εκπαιδεύσεις\" (batches) ανά epoch\n",
    "\n",
    "validation_data=(X_test, y_test) -> \"Μετά από κάθε epoch, δοκίμασε το μοντέλο σε αυτά τα δεδομένα\"\n",
    "ώστε να δούμε πόσο καλά γενικεύει σε άγνωστα δεδομένα.\n",
    "\n",
    "\n",
    "Πχ accuracy: 0.8534 - loss: 0.4282 - val_accuracy: 0.9670 - val_loss: 0.13\n",
    "\n",
    "Το μοντέλο πέτυχε 85.34% ακρίβεια στα δεδομένα εκπαίδευσης. Δηλαδή ταξινόμησε σωστά το 85.34% των email του X_train.\n",
    "\n",
    "loss: 0.4282 Το σφάλμα (loss) του μοντέλου στα εκπαιδευτικά δεδομένα.Αντιπροσωπεύει πόσο \"μακριά\" είναι οι προβλέψεις του μοντέλου από τις σωστές απαντήσεις.\n",
    "\n",
    "val_accuracy: 0.9670 -> Το μοντέλο πέτυχε 96.70% ακρίβεια στα δεδομένα επικύρωσης (X_test).\n",
    "\n",
    "val_loss 0.13 -> validation loss Το μικρό val_loss σημαίνει ότι οι προβλέψεις του είναι κοντά στην πραγματικότητα ακόμα και σε άγνωστα δεδομένα.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0c62e-1bd1-4a78-bf1c-50b841018714",
   "metadata": {},
   "source": [
    "### περιγραφή αποτελεσμάτων RNN\n",
    "\n",
    "Το μοντέλο μας RNN εκπαιδεύτηκε για Epoch με στόχο τη δυαδική ταξινόμηση email (π.χ. spam ή ham). Από την αρχή της εκπαίδευσης, παρουσίασε υψηλή ακρίβεια, με το train accuracy να ξεκινά στο 88.5% και να φτάνει το 97.2% στο τέλος. Το validation accuracy διατηρήθηκε εξίσου υψηλό καθ' όλη τη διάρκεια, με τιμές από 96.0% έως 97.5%.\n",
    "\n",
    "Το loss (σφάλμα) μειώθηκε σημαντικά στο training set, δείχνοντας ότι το μοντέλο μαθαίνει καλά τα δεδομένα του. Αντίστοιχα, και το validation loss παρέμεινε σε χαμηλά επίπεδα (0.11–0.13), γεγονός που δείχνει ότι το μοντέλο γενικεύει καλά και δεν παρουσιάζει μεγάλες διακυμάνσεις.\n",
    "\n",
    "Συμπέρασμα, το RNN μοντέλο μας παρουσιάζει πολύ καλή απόδοση και τα αποτελέσματα είναι πολύ ικανοποιητικά, με σταθερή πορεία μάθησης, υψηλή ακρίβεια και χωρίς εμφανή σημάδια υπερεκπαίδευσης (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b7515-310b-4e93-94e3-57a8df93b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc780a-0282-4fa8-8b71-8e55ec1a10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c3c01-8128-4b56-b388-5c016dbc1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Precision : {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f77f4-8328-47b0-ae28-0f3c449ef23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Recall    : {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3097477-228b-47fa-8e4a-49d8b2d556ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"F1 Score  : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c8b45-80a6-4224-bef6-3d08196d089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Προσθήκη αποτελεσματων για το RNN\n",
    "accuracy_scores[\"RNN\"] = accuracy\n",
    "precision_scores[\"RNN\"] = precision\n",
    "recall_scores[\"RNN\"] = recall\n",
    "f1_scores[\"RNN\"] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067dc5a-3f97-4f79-b6bc-5a99cd8e1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55c3d0-55d4-47df-bf1c-016340c2e4b7",
   "metadata": {},
   "source": [
    "# Μεθοδολογία\n",
    "\n",
    "Η μεθοδολογία που ακολουθήθηκε στην παρούσα εργασία βασίζεται σε ένα πλήρες pipeline επεξεργασίας φυσικής γλώσσας και εφαρμογής αλγορίθμων ταξινόμησης για την ανίχνευση (spam) kai μηνυμάτων email.\n",
    "\n",
    "### Συλλογή και Προεπεξεργασία Δεδομένων\n",
    "\n",
    "Αρχικά, εισάγαμε ένα σύνολο δεδομένων που περιλάμβανε μηνύματα ηλεκτρονικής αλληλογραφίας, ταξινομημένα ως \"spam\" ή \"ham\". Η προεπεξεργασία περιλάμβανε:\n",
    "\n",
    "Αφαίρεση URLs, emojis και emoticons\n",
    "\n",
    "Μετατροπή όλων των χαρακτήρων σε πεζά\n",
    "\n",
    "Eφαρμογή tokenization\n",
    "\n",
    "Στόχος ήταν η εξαγωγή πιο καθαρών και γενικεύσιμων χαρακτηριστικών από το κείμενο.\n",
    "\n",
    "### Αναπαράσταση Κειμένου\n",
    "\n",
    "Ανάλογα με τον αλγόριθμο, χρησιμοποιήσαμε διαφορετικές τεχνικές αναπαράστασης:\n",
    "\n",
    "Vectorization με CountVectorizer για τον αλγόριθμο Multinomial Naive Bayes\n",
    "\n",
    "Word2Vec για τη μετατροπή των λέξεων σε διανύσματα πυκνής αναπαράστασης (embeddings), χρησιμοποιημένα σε ταξινομητές όπως Logistic Regression\n",
    "\n",
    "Tokenization & Padding για χρήση σε RNN (Recurrent Neural Networks) μέσω TensorFlow\n",
    "\n",
    "### Κατασκευή και Εκπαίδευση Μοντέλων\n",
    "\n",
    "Υλοποιήθηκαν και συγκρίθηκαν διαφορετικά μοντέλα ταξινόμησης:\n",
    "\n",
    "Multinomial Naive Bayes (MNB)\n",
    "Χρησιμοποιήθηκε για count-based δεδομένα, ιδιαίτερα αποδοτικός σε κείμενα.\n",
    "\n",
    "Logistic Regression με Word2Vec Embeddings\n",
    "Εφάρμοσε μέσο όρο διανυσμάτων ανά μήνυμα και εκπαίδευσε γραμμικό μοντέλο.\n",
    "\n",
    "RNN (Simple Recurrent Neural Network)\n",
    "Χρησιμοποιήθηκε μοντέλο με Embedding layer, SimpleRNN και πυκνό layer εξόδου.\n",
    "\n",
    "Κάθε μοντέλο εκπαιδεύτηκε με χρήση train/test split και stratified sampling για ισορροπία κατηγοριών.\n",
    "\n",
    "### Αξιολόγηση Μοντέλων\n",
    "\n",
    "Τα μοντέλα αξιολογήθηκαν με τις ακόλουθες μετρικές:\n",
    "\n",
    "Accuracy – Ποσοστό σωστών προβλέψεων\n",
    "\n",
    "Precision – Πόσα από τα spam που προβλέψαμε είναι όντως spam\n",
    "\n",
    "Recall – Πόσα από τα πραγματικά spam τα εντόπισε το μοντέλο\n",
    "\n",
    "F1-Score – Ο συνδυασμός precision και recall\n",
    "\n",
    "Confusion Matrix – Γραφική αναπαράσταση σωστών/λανθασμένων προβλέψεων\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c94c4-c063-4f6c-8406-ba498a6b7d40",
   "metadata": {},
   "source": [
    "# Συνολικές Μετρίσεις και Αξιολόγηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f6587-a917-4081-b500-fef0cb4bcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot για κάθε μετρική\n",
    "def plot_metric(metric_dict, title, color):\n",
    "    models = list(metric_dict.keys())\n",
    "    scores = list(metric_dict.values())\n",
    "\n",
    "    matplotlib.pyplot.figure(figsize=(8, 5))\n",
    "    bars = matplotlib.pyplot.bar(models, scores, color=color, edgecolor='black', width=0.6)\n",
    "\n",
    "    # Εμφάνιση τιμής πάνω από κάθε μπάρα\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        matplotlib.pyplot.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f\"{yval:.3f}\",\n",
    "                 ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "    matplotlib.pyplot.title(title, fontsize=14, weight='bold')\n",
    "    matplotlib.pyplot.ylim(0.0, 1.05)\n",
    "    matplotlib.pyplot.ylabel(\"Score\", fontsize=12)\n",
    "    matplotlib.pyplot.xticks(fontsize=11)\n",
    "    matplotlib.pyplot.yticks(fontsize=11)\n",
    "    matplotlib.pyplot.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    matplotlib.pyplot.box(False)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e45b7-de95-49d0-977c-751525d7281f",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156dc4d-993b-4289-b3e1-a87c7398c78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(accuracy_scores, \"Accuracy Comparison\", \"cornflowerblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3bec2f-5435-49be-ac10-f198e9c8a855",
   "metadata": {},
   "source": [
    "### Συμπέρασμα για τη συνολική ακρίβεια (Accuracy)\n",
    "\n",
    "Η σύγκριση toy accuracy ανάμεσα στα τρία μοντέλα — Naive Bayes, Word2Vec με Logistic Regression, και RNN — αποκαλύπτει ότι όλα τους έχουν εξαιρετικές επιδόσεις στην κατηγοριοποίηση των email σε spam και ham. Το μοντέλο Naive Bayes ξεχωρίζει με την υψηλότερη ακριβεια, φτάνοντας το 0.979, ακολουθούμενο από το RNN με 0.973, ενώ το Word2Vec + Logistic Regression αγγίζει το 0.969. Οι διαφορές τους είναι μικρές, υποδεικνύοντας ότι όλα τα μοντέλα είναι αποτελεσματικά για το συγκεκριμένο προβλημα. Παρ' όλα αυτά, το Naive Bayes έχει μια ελαφριά υπεροχή στην ακρίβεια, πιθανώς λόγω της απλότητας των δεδομένων και της καταλληλότητας της υπόθεσης ανεξαρτεισίας σε αυτή την περίπτωση. Το RNN παραμένει ισχυρό, ειδικά αν σκοπεύουμε να επεκταθούμε σε πιο σύνθετα ή μεγαλύτερα σύνολα δεδομένων."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704074a-50bd-4343-b71e-7083b797e125",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a68d9a-81a2-48b3-ac6b-d50fe0854ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(precision_scores, \"Precision Comparison\", \"seagreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41318c9-d219-4455-a5b3-dc8847a209a8",
   "metadata": {},
   "source": [
    "### Συμπέρασμα για την ακρίβεια θετικών προβλέψεων (Precision)\n",
    "\n",
    "Η σύγκριση των μοντέλων όσον αφορά την Precision — δηλαδή την ικανότητά τους να εντοπίζουν σωστά τα spam emails χωρίς να κάνουν πολλά λaθη (false positives) — δείχνει ότι το RNN μοντέλο ξεχωρίζει. Το RNN πέτυχε precision 0.975, που σημαίνει ότι όταν χαρακτηρίζει ένα email ως spam, είναι σχεδόν πάντα σωστό.\n",
    "\n",
    "Ακολουθεί το μοντέλο Word2Vec + Logistic Regression με 0.929, που είναι επίσης πολύ υψηλή τιμή, ενώ το Naive Bayes έχει την χαμηλότερη τιμη με 0.920. Αν και οι αριθμοί φαίνονται κοντά, στην πράξη αυτό μπορεί να σημαίνει λιγότερες λανθασμένες ειδοποιήσεις για τον χρήστη (false alarms).\n",
    "\n",
    "Συνολικά, το RNN αποδεικνύει ότι έχει την καλύτερη ακρίβεια στις θετικές προβλεψεις, κάνοντάς το πιο αξιοπίστο στην αποφυγή \"ψευδών spam\" — ένα κρίσιμο χαρακτηριστικό για τις εφαρμογές φίλτρων email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efade1b9-9c6f-4617-a1d0-b0d4d94697de",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76f5c2-2aa9-4ee0-8709-2b5eb4576f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(recall_scores, \"Recall Comparison\", \"darkorange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf8a8f-2ec0-4456-a731-ec22293b0e0c",
   "metadata": {},
   "source": [
    "### Συμπέρασμα για το Recall\n",
    "\n",
    "Η σύγκριση των μοντέλων όσον αφορά το Recall — δηλαδή την ικανότητά τους να εντοπίζουν όλα τα πραγματικά θετικά περιστατικά (spam emails) — αποκαλύπτει ότι το μοντέλο Naive Bayes έχει την καλήτερη απόδοση με τιμή 0.925. Αυτό σημαίνει ότι το μοντέλο μπορεί να αναγνωρίσει το 92.5% των πραγματικών spam μηνυμάτων, κάτι που είναι εξαιρετικά σημαντικό για ένα φίλτρο ανεπιθύμητης αλληλογραφίας.\n",
    "\n",
    "Ακολουθεί το μοντέλο Word2Vec + Logistic Regression με recall 0.834, και στη συνέχεια το RNN με recall 0.818. Οι χαμηλότερες τιμές για Word2Vec και RNN δείχνουν ότι χάνουν περισσότερα πραγματικά spam μηνύματα (false negatives), κάτι που σε πραγματικές συνθήκες θα μπορούσε να οδηγήσει σε ανεπιθύμητα emails που περνούν απαρατήρητα.\n",
    "\n",
    "Συμπερασματικά, αν η προτεραιότητα είναι να μην χάνεται κανένα spam email, τότε το Naive Bayes είναι η καλύτερη επιλογή. Ωστόσο, θα πρέπει να εξεταστεί και η precision, ώστε να βρεθεί η σωστή ισορροπία μεταξύ ευαισθησίας και ακρίβειας."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c57ceb-abe6-4c4f-ab20-a27d2d85b655",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7974d55-cb8c-4c1a-ba7e-780cb7c8cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(f1_scores, \"F1 Score Comparison\", \"firebrick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032e446-6e9f-4a37-b544-df7178f3d51c",
   "metadata": {},
   "source": [
    "### Συμπέρασμα για το F1-Score\n",
    "\n",
    "Η σύγκριση των μοντέλων με βάση το F1-Score είναι μια μέτρηση που βρίσκει την ισορροπία ανάμεσα στην ακρίβεια (precision) και την ευαισθησία (recall). Στην ανάλυσή μας, βλέπουμε ότι το Naive Bayes πετυχαίνει τον καλύτερο συνδυασμό με F1-Score 0.923. Αυτό το αποτέλεσμα δεν μας ξαφνιάζει, καθώς το Naive Bayes είχε ήδη δείξει υψηλή ακρίβεια (0.920) και εξαιρετική ευαισθησία (0.925), πράγμα που σημαίνει ότι είναι και ακριβές και ευαίσθητο στην ανίχνευση των spam.\n",
    "\n",
    "Από την άλλη, το RNN δείχνει υψηλή ακρίβεια (0.975) — που σημαίνει ότι είναι εξαιρετικό στο να εντοπίζει σωστά τις περιπτώσεις spam χωρίς να κάνει πολλά λάθη — αλλά έχει πιο περιορισμένη ευαισθησία (0.818), που σημαίνει ότι \"χάνει\" κάποια spam μηνύματα. Αν και αυτό το trade-off οδηγεί σε ελαφρώς χαμηλότερο F1 (0.890), παραμένει μια πολύ ισχυρή επιλογή, ειδικά όταν είναι κρίσιμο να μην κατηγοριοποιούνται λανθασμένα τα κανονικά μηνύματα ως spam.\n",
    "\n",
    "Το μοντέλο Word2Vec + Logistic Regression έχει ισορροπημένες αλλά ελαφρώς χαμηλότερες επιδόσεις σε όλα τα metrics (ακρίβεια: 0.929, ευαισθησία: 0.834, F1: 0.879), και έτσι κατατάσσεται τρίτο σε συνολική απόδοση."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6e03d-a47b-4a96-9f6d-abeeaa5495a9",
   "metadata": {},
   "source": [
    "# Τελική εκτίμηση"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bab93-9c90-4dad-9fed-6f10f4a446cb",
   "metadata": {},
   "source": [
    "Αν ο στόχος είναι να μην χάσουμε κανένα spam, τότε το Naive Bayes είναι η καλύτερη επιλογή, καθώς έχει πολύ υψηλό recall.\n",
    "\n",
    "Αν, όμως, προτεραιότητα είναι να μειωθούν οι ψευδείς ειδοποιήσεις (false positives), τότε το RNN προσφέρει καλύτερη precision, αν και θυσιάζει την recall.\n",
    "\n",
    "Το Word2Vec είναι σταθερό και ισορροπημένο, αλλά λίγο πιο αδύναμο σε σύγκριση με τα άλλα δύο.\n",
    "\n",
    "Συνολικά, το Naive Bayes προσφέρει την πιο ισορροπημένη απόδοση, ειδικά αν το αξιολογήσουμε με βάση το F1-score, το οποίο δίνει ίση σημασία στην ακριβή και πλήρη ανίχνευση των spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
